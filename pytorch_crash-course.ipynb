{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmEbgug3P0OA",
        "outputId": "a27eac29-96e2-4136-a091-5d2893555be6",
        "tags": [
          "dependencies"
        ]
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Dependencies\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMPyhb0dJuh3"
      },
      "source": [
        "# 0 - PyTorch fundamentals\n",
        "Following along with Daniel Bourke's \"Learn PyTorch for deep leraning in a day. Literally.\" video on youtube."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "311waH8yP7p3"
      },
      "source": [
        "## 0.1 - Introduction to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyBbEzcUQE7o",
        "outputId": "a651c001-7c0c-4408-f995-43fd877bcafe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "'''\n",
        "Tensors are one of the most common data classes in PyTorch,\n",
        "see documentation on tensors for more.\n",
        "'''\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqYoyTV2QIlI",
        "outputId": "ae8ca62e-0031-4948-a82e-7b38da83020e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim # a scalar has no dimensions, it's just the number 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ud6akv-7Q1kv",
        "outputId": "f68e8a56-09e6-43e3-939c-a3aceaa96859"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can get the number back as a python int with:\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIBdjBYmQ5Gm",
        "outputId": "10ca95a5-24fa-46bf-b15f-d74d2fcb39e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vectors\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XafWzWddRCVw",
        "outputId": "7689fc7a-20b0-43a3-f6d8-6005a44a4908"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim # a vector has 1 dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2N4YadPROrG",
        "outputId": "12a933f6-455e-42a2-ab93-c4154011de52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape # but the shape of the vector is 2, i.e. 2 elements x 1 dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8LA47QrRa6z",
        "outputId": "b14c38e4-5445-47c4-9082-d1d0d7c899eb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# MATRIX (capitalized for a reason)\n",
        "MATRIX = torch.tensor([[7,8],\n",
        "                       [9,10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvIUQIDpRiSe",
        "outputId": "69599595-f7f8-4a73-8600-6b6aea2e96ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim # a matrix has 2 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAnGBjfORtuL",
        "outputId": "8b60bf76-d696-4fdf-ab2a-174502bb28c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape # with a shape of 2x2, or 2 elements by 2 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyIfGHcMRvZ_",
        "outputId": "5d0cf077-013f-498e-d63d-dff8f98be799"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 4, 5],\n",
              "         [4, 5, 6]]])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR (also capitalized for a reason)\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [3,4,5],\n",
        "                        [4,5,6]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sG8kmPGSC1x",
        "outputId": "1c2600d6-f54e-4ba8-83e5-0cfc0be9a8e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim # this tensor has 3 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFaHPQhzSG76",
        "outputId": "b0b24e1a-691d-4432-91c8-961078bc75ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'''\n",
        "and a shape of 1x3x3\n",
        "because it is a 3x3 matrix, encased into 1 dimension.\n",
        "Think about the brackets and how indexing them would return.\n",
        "i.e. returning index [0] returns a single item, the entire 3x3 matrix.\n",
        "'''\n",
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfXaIOp5SMdg"
      },
      "source": [
        "\n",
        " | name | dimensions | lower or upper case |\n",
        "| -- | -- | -- |\n",
        "| scalar | 0 | lower case (a) |\n",
        "| vector | 1 | lower case (y) |\n",
        "| matrix | 2 | upper case (Q) |\n",
        "| tensor | any | upper case (X) |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U602kEokTahb"
      },
      "source": [
        "## 0.2 - Random tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "why random tensors?\n",
        "Random tensors are a big part of PyTorch because the way many neural networks (NN) learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> loop ad infinitum:`\n",
        "\n",
        "\n",
        "`(look at data -> update random numbers -> look at data -> update random numbers ->)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495_C2cWUN64",
        "outputId": "3c7fc988-f0f6-48e4-c826-3e3908eb3efe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6805, 0.5524, 0.7945, 0.2576],\n",
              "        [0.9794, 0.1941, 0.5377, 0.7933],\n",
              "        [0.4224, 0.9443, 0.9274, 0.3598]])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor of size or shape\n",
        "# random tensor of size (3,4)\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor # 3 elements, 4 deep (i.e. 3 x 4-element vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SyNcxTLTUZQy",
        "outputId": "c4fc2210-3872-4555-e571-c55f405430b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.6364, 0.0663, 0.1963, 0.2635, 0.9553, 0.7958, 0.9118, 0.2964,\n",
              "          0.0061, 0.7412],\n",
              "         [0.5688, 0.1555, 0.1630, 0.6196, 0.9512, 0.6794, 0.6971, 0.2679,\n",
              "          0.2692, 0.6257],\n",
              "         [0.4463, 0.6241, 0.0757, 0.2507, 0.2752, 0.1184, 0.7453, 0.8574,\n",
              "          0.9678, 0.0983],\n",
              "         [0.0958, 0.3229, 0.8760, 0.3111, 0.7218, 0.7683, 0.1087, 0.9923,\n",
              "          0.3560, 0.4227],\n",
              "         [0.8560, 0.2167, 0.9006, 0.7461, 0.7490, 0.6860, 0.4288, 0.3845,\n",
              "          0.7519, 0.7475],\n",
              "         [0.0408, 0.2080, 0.9331, 0.1151, 0.1764, 0.1510, 0.3464, 0.4892,\n",
              "          0.8101, 0.5210],\n",
              "         [0.8248, 0.0430, 0.8541, 0.7296, 0.0055, 0.5293, 0.1847, 0.3258,\n",
              "          0.4641, 0.9918],\n",
              "         [0.6583, 0.0898, 0.9128, 0.8830, 0.5350, 0.1027, 0.7965, 0.0496,\n",
              "          0.7980, 0.0511],\n",
              "         [0.6344, 0.8710, 0.3288, 0.0629, 0.5193, 0.0769, 0.7967, 0.7998,\n",
              "          0.8244, 0.2102],\n",
              "         [0.7879, 0.7952, 0.3704, 0.4859, 0.3702, 0.3559, 0.0215, 0.0189,\n",
              "          0.8877, 0.4540]]])"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor = torch.rand(1,10,10)\n",
        "random_tensor # 1 element composed of 10 individual 10-element vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jS4kwiu1Uv6r",
        "outputId": "46911c0a-c0dd-4f77-f8f5-6e9b597a132d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a random tensor with similar shape to an image tensor\n",
        "\n",
        "# height, width, color channels (R, G, B)\n",
        "# not necessarily always this order\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMaqcRlSVLEF",
        "outputId": "436f4f38-c867-4c86-e0a7-f82b503f4373"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[[0.1926, 0.3112, 0.5714, 0.6479, 0.5418],\n",
              "           [0.5288, 0.5626, 0.1920, 0.8414, 0.5355],\n",
              "           [0.3492, 0.0990, 0.2362, 0.8896, 0.6123],\n",
              "           [0.6687, 0.2505, 0.6890, 0.0069, 0.3693]],\n",
              "\n",
              "          [[0.8972, 0.4404, 0.2713, 0.1588, 0.5622],\n",
              "           [0.7863, 0.8578, 0.1259, 0.8301, 0.0264],\n",
              "           [0.8544, 0.9668, 0.9897, 0.7940, 0.6163],\n",
              "           [0.3618, 0.9629, 0.6518, 0.4611, 0.7780]],\n",
              "\n",
              "          [[0.1799, 0.0212, 0.8506, 0.1346, 0.7098],\n",
              "           [0.4207, 0.8786, 0.4291, 0.1639, 0.3011],\n",
              "           [0.8862, 0.0941, 0.0500, 0.0892, 0.6325],\n",
              "           [0.8116, 0.7563, 0.7733, 0.9669, 0.7805]]],\n",
              "\n",
              "\n",
              "         [[[0.7845, 0.7647, 0.2717, 0.3462, 0.3721],\n",
              "           [0.9759, 0.2582, 0.6814, 0.2667, 0.8110],\n",
              "           [0.7834, 0.8318, 0.4948, 0.7349, 0.9664],\n",
              "           [0.4082, 0.3307, 0.7469, 0.9627, 0.4184]],\n",
              "\n",
              "          [[0.4656, 0.4783, 0.0155, 0.8484, 0.3202],\n",
              "           [0.9060, 0.8003, 0.9755, 0.8250, 0.7258],\n",
              "           [0.1189, 0.8899, 0.7305, 0.6655, 0.9202],\n",
              "           [0.9502, 0.7587, 0.3897, 0.6414, 0.5867]],\n",
              "\n",
              "          [[0.4650, 0.5023, 0.6367, 0.3815, 0.5566],\n",
              "           [0.6108, 0.6278, 0.7182, 0.0536, 0.1543],\n",
              "           [0.3410, 0.9636, 0.4096, 0.7585, 0.5507],\n",
              "           [0.3486, 0.2978, 0.6503, 0.2105, 0.3163]]]]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a random tensor of any size and shape\n",
        "\n",
        "'''\n",
        "1 element composed of(\n",
        "  2 elements composed of(\n",
        "    3 elements composed of(\n",
        "      4 elements composed of(\n",
        "        5 element vectors\n",
        "        )\n",
        "      )\n",
        "    )\n",
        "  )\n",
        ")\n",
        "'''\n",
        "my_random_tensor = torch.rand(size = (1, 2, 3, 4, 5))\n",
        "my_random_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvq5Wf4KVyLR"
      },
      "source": [
        "### Zeroes and Ones tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "xh6pA2hRWU3M"
      },
      "outputs": [],
      "source": [
        "# create a tensor of all zeros\n",
        "\n",
        "# useful for creating a mask\n",
        "zero = torch.zeros(size = (3, 4))\n",
        "random_tensor = torch.rand(size = (3, 4))\n",
        "# can use that zero tensor to zero out another tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS-UrCiTWi1p"
      },
      "source": [
        "### Creating a range of tensors and tensors-like\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_8245/2147303806.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  torch.range(0,10)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.range() may be deprecated\n",
        "torch.range(0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instead use torch.arange()\n",
        "torch.arange(0,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# can also create steps with torch.arange()\n",
        "stepped_range = torch.arange(start=0, end=1000, step=77)\n",
        "stepped_range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 77, 154, 231, 308, 385, 462, 539, 616, 693, 770])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# could also get funky with it\n",
        "# like in this instance, if you wanted exactly 10 multiples of 77\n",
        "step_size = 77\n",
        "stepped_range = torch.arange(start = step_size, end = 11*step_size, step = step_size) # 11 because we want 10 multiples. the end is exclusive, meaning 11 is not included\n",
        "stepped_range"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensors-like\n",
        "Say you have a shape that you want to replicate, but don't want to explicitly define what that shape should be"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10])\n",
            "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
            "\n",
            "torch.Size([10])\n",
            "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "\n",
            "torch.Size([10])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# tensors like\n",
        "one_to_ten = torch.arange(start=1, end=11, step=1)\n",
        "print(one_to_ten.shape)\n",
        "print(one_to_ten)\n",
        "\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten)\n",
        "print(f'\\n{ten_zeros.shape}')\n",
        "print(ten_zeros)\n",
        "\n",
        "ten_ones = torch.ones_like(input=one_to_ten)\n",
        "print(f'\\n{ten_ones.shape}')\n",
        "print(ten_ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.3 - Tensor datatypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Tensor datatypes is one of the 3 big errors you'll run into with Pytorch and deep learning:\n",
        "1. Tensors not right datatype\n",
        "2. Tensors not right shape\n",
        "3. Tensors not on the right device\n",
        "\n",
        "float32 is referred to as single precision floating point\n",
        "\n",
        "\n",
        "float16 is referred to as half precision floating point\n",
        "\n",
        "\n",
        "more precision = more computing power required\n",
        "\n",
        "\n",
        "less precision = less computing power required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "# when unspecified, the default dtype is float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0])\n",
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# it's good to explicitly set the dtype, device, and required gradient\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
        "                               dtype=None, # what datatype the tensor should be\n",
        "                               device=None, # what device the tensor should be on\n",
        "                               requires_grad=True # whether or not to track gradients\n",
        "                               )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[98], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m cpu_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m gpu_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mcpu_tensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgpu_tensor\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "# if you try to do tensor operations on tensors not on the same device, you'll get an error\n",
        "cpu_tensor = torch.tensor([1,2,3], device='cpu')\n",
        "gpu_tensor = torch.tensor([1,2,3], device='cuda')\n",
        "\n",
        "cpu_tensor + gpu_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "some mismatched datatypes will result in an error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.4 - Getting information from tensors (tensor attributes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2116, 0.5383, 0.4137, 0.9415],\n",
              "        [0.0590, 0.1405, 0.4789, 0.1742],\n",
              "        [0.1329, 0.6018, 0.8005, 0.7299]])"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "some_tensor = torch.rand(3, 4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.2116, 0.5383, 0.4137, 0.9415],\n",
            "        [0.0590, 0.1405, 0.4789, 0.1742],\n",
            "        [0.1329, 0.6018, 0.8005, 0.7299]])\n",
            "Datatype: torch.float32\n",
            " Shape: torch.Size([3, 4])\n",
            " Device: cpu\n"
          ]
        }
      ],
      "source": [
        "# find out details about some_tensor\n",
        "print(some_tensor)\n",
        "print(f'Datatype: {some_tensor.dtype}\\n',\n",
        "        f'Shape: {some_tensor.shape}\\n',\n",
        "        f'Device: {some_tensor.device}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n",
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "# change the device a pytorch tensor is on\n",
        "print(some_tensor.device)\n",
        "cuda_some_tensor = some_tensor.to(device='cuda')\n",
        "print(cuda_some_tensor.device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.5 - Manipulating tensors (tensor operations)\n",
        "https://pytorch.org/docs/stable/generated/torch.matmul.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.51 - Basic Arithmetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a tensor\n",
        "tensor = torch.tensor([1, 2, 3], dtype=torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13], dtype=torch.int32)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# addition\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7], dtype=torch.int32)"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# subtraction\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30], dtype=torch.int32)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# element-wise multiplication\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30], dtype=torch.int32)"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# There are also inbuilt functions for tensor operations\n",
        "torch.mul(tensor, 10) # multiplication (element-wise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.5000, 1.0000, 1.5000])"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Division\n",
        "tensor / 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 0.52 Matrix multiplication\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "- Element-wise multiplication (x*y)\n",
        "- Matrix multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3], dtype=torch.int32) * tensor([1, 2, 3], dtype=torch.int32)\n",
            "Equals: tensor([1, 4, 9], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "print(tensor, \"*\", tensor)\n",
        "print(f'Equals: {tensor*tensor}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3], dtype=torch.int32)\n",
            "tensor*tensor with matrix multiplication: 14\n"
          ]
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "print(tensor)\n",
        "print(f'tensor*tensor with matrix multiplication: {torch.matmul(tensor, tensor)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The result is 14 because:\n",
        "1*1 + 2*2 + 3*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14, dtype=torch.int32)\n",
            "CPU times: user 1.6 ms, sys: 389 µs, total: 1.99 ms\n",
            "Wall time: 1.47 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# or in a for loop:\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 319 µs, sys: 77 µs, total: 396 µs\n",
            "Wall time: 321 µs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14, dtype=torch.int32)"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even with such a small tensor, it is 10x slower to use the for loop than the PyTorch matrix multiplication function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Rules that must be satisfied with matrix multiplication\n",
        "1. The **inner dimensions** must match: (@ is the symbol for matrix multiplication)\n",
        "* `(3, 2) @ (3, 2)` won't work\n",
        "* `(2, 3) @ (3, 2)` will work\n",
        "* `(3, 2) @ (2, 3)` will work\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`torch.matmul(torch.rand(3, 2), torch.rand(3, 2))`\n",
        "\n",
        "RuntimeError: ***mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)***\n",
        "\n",
        "This happens because when mat1 row is multiplied by mat2 column, mat1 has 3 values, and mat2 has only 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. The resulting matrix has the shape of the **outer dimensions**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`(2, 3) @ (3, 2)` --> (2, 2)\n",
        "\n",
        "**inner dimensions** match; rule 1 satisfied.\n",
        "\n",
        "so the resulting matrix will have dimensions (2, 2) from the **outer dimensions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4234, 0.2344],\n",
              "        [1.0673, 0.6612]])"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# (2, 3) @ (3, 2)\n",
        "torch.matmul(torch.rand(2, 3), torch.rand(3, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One of the most common errors in deep learning: shape errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[122], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# torch.mm is a shortcut for matmul\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# torch.mm is a shortcut for matmul\n",
        "torch.mm(tensor_A, tensor_B)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We were creating tensors on the fly before, but these already exist, how can we change their shape?\n",
        "\n",
        "transposition!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7, 10],\n",
              "        [ 8, 11],\n",
              "        [ 9, 12]])"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8,  9],\n",
              "        [10, 11, 12]])"
            ]
          },
          "execution_count": 125,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, having transposed tensor_B (tensor_B.T), we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " tensor_A.shape: torch.Size([3, 2])\n",
            " tensor_B.T.shape: torch.Size([2, 3])\n",
            "     or torch.Size([3, 2]) @ torch.Size([2, 3]) \n",
            "\n",
            " Inner dimensions match ((3, 2) @ (2, 3)),\n",
            " resulting matrix has shape of outer dimensions (3, 3)\n",
            "\n",
            " torch.mm(tensor_A, tensor_B.T):\n",
            " tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n"
          ]
        }
      ],
      "source": [
        "print(f' tensor_A.shape: {tensor_A.shape}\\n',\n",
        "      f'tensor_B.T.shape: {tensor_B.T.shape}\\n',\n",
        "      f'    or {tensor_A.shape} @ {tensor_B.T.shape}',\n",
        "      f'\\n\\n Inner dimensions match ((3, 2) @ (2, 3)),\\n resulting matrix has shape of outer dimensions (3, 3)'\n",
        "      f'\\n\\n',\n",
        "      f'torch.mm(tensor_A, tensor_B.T):\\n {torch.mm(tensor_A, tensor_B.T)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.6 - Finding the min, max, mean, sum, etc. (Tensor Aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a tensor\n",
        "\n",
        "# torch.arange(start, end, step)\n",
        "x = torch.arange(0, 100, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(0), tensor(0))"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the mein\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(90), tensor(90))"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[134], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# find the mean\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, x\u001b[38;5;241m.\u001b[39mmean()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ],
      "source": [
        "# find the mean\n",
        "torch.mean(x), x.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here finally is a \"Tensor not the right datatype\" errors.\n",
        "\n",
        "The tensor we created is of type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'torch.LongTensor'"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.type()\n",
        "# torch.int64 or torch.LongTensor, or in english it's a 64-bit signed integer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The documentation doesn't explicitly state the dtype the data should be in, but from the RuntimeError we can see this should either be a floating point or a complex dtype\n",
        "\n",
        "The floating points: (complex dtypes include things like imaginary literals, likely unnecessary)\n",
        "\n",
        "| Data Type | dtype | \n",
        "| --- | --- |\n",
        "| 32-bit float | torch.float32 or torch.float |\n",
        "| 64-bit float | torch.float64 or torch.double |\n",
        "| 16-bit float | torch.float16 or torch.half |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(45.), tensor(45.))"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# torch.mean() requires a tensor of float numbers\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(450), tensor(450))"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.7 - Finding the positional min ( argmin() ) and max ( argmax() )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Positional max and min return the index value of the maximum and minimum value within a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  1,  11,  21,  31,  41,  51,  61,  71,  81,  91, 101])"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(1, 111, 10)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# argmin() returns the index of the min value\n",
        "x.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# we can then use that argmin() value to get the actual min value\n",
        "x[x.argmin()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "execution_count": 153,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# argmax() returns the index of the max value\n",
        "x.argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(101)"
            ]
          },
          "execution_count": 154,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and similarly we can use this index to get the actual max value\n",
        "x[x.argmax()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is helpful for things like the softmax activation function, because we really don't care about **what** the maximum value is, as much as ***where*** the maximum value is"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0.8 - Reshaping, stacking, squeezing and unsqueezing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - Return a view of an input tensor of certain shape bu tkeep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other (vstack for vertical stack; there are other types of stacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
